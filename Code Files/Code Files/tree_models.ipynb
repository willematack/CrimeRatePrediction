{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "65575545-608b-40b3-9d32-800ed57f3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing, svm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8424f6c0-692b-4179-b092-cfa5cbc0413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv(r\"C:\\Users\\wille\\Documents\\AppliedStats\\Project\\CleanData\\X.csv\")\n",
    "X_full = scaler.fit_transform(X_full)\n",
    "X_violent = pd.read_csv(r\"C:\\Users\\wille\\Documents\\AppliedStats\\Project\\Vars\\X_refined_violent.csv\", index_col=0).values\n",
    "X_n_violent = pd.read_csv(r\"C:\\Users\\wille\\Documents\\AppliedStats\\Project\\Vars\\X_refined_n_violent.csv\", index_col=0).values\n",
    "Y = pd.read_csv(r\"C:\\Users\\wille\\Documents\\AppliedStats\\Project\\Vars\\Y.csv\", index_col = 0)\n",
    "target_violent = Y.Total_Violent.values\n",
    "target_n_violent = Y[\"Non.Violent\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91d485d6-ac27-4e26-b9a1-3c7408efd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_full):\n",
    "    X_train, X_test = X_full[train_index], X_full[test_index]\n",
    "    y_train, y_test = target_violent[train_index], target_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "rf_fv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9a01365-d721-4963-a104-ff507ea982e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378.39971717541965"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d82afe77-141a-438e-a43a-19a067d2e589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    3    4 ... 2212 2213 2214]\n",
      "[   0    1    2 ... 2212 2213 2214]\n",
      "[   0    1    2 ... 2211 2212 2214]\n",
      "[   0    1    2 ... 2211 2212 2213]\n",
      "[   0    1    2 ... 2211 2213 2214]\n",
      "[   0    1    2 ... 2212 2213 2214]\n",
      "[   0    1    2 ... 2212 2213 2214]\n",
      "[   0    1    2 ... 2212 2213 2214]\n",
      "[   1    2    3 ... 2212 2213 2214]\n",
      "[   0    1    2 ... 2212 2213 2214]\n"
     ]
    }
   ],
   "source": [
    "mse_scores = []\n",
    "rf_model = RandomForestRegressor(n_estimators=200,max_features = 'log2')\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X_violent):\n",
    "    print(train_index)\n",
    "    X_train, X_test = X_violent[train_index], X_violent[test_index]\n",
    "    y_train, y_test = target_violent[train_index], target_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "rf_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4f52f1dd-f57a-4cee-9202-743670d17b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366.4523611644714"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c632ed1-b705-41f4-b105-98e4a3859960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5b4d26c7-e6f6-4bba-a955-a6ad9cc4d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_estimators = 20000\n",
    "\n",
    "bst = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=num_estimators,\n",
    "    max_depth = 5\n",
    ")\n",
    "\n",
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_full):\n",
    "    X_train, X_test = X_full[train_index], X_full[test_index]\n",
    "    y_train, y_test = target_violent[train_index], target_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    bst.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = bst.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "bst_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6f65238d-8a2f-4998-b742-47dc82909f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378.28901811910174"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6ab1ae6d-9ad2-453f-8e20-fb49acf524de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c0c8b9a8-a2b8-4738-a5cb-633f58a614e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "lgm = LGBMRegressor(boosting_type='gbdt',\n",
    "                   num_leaves=17,\n",
    "                   learning_rate = 0.1,\n",
    "                   n_estimators=100,\n",
    "                   verbose=0)\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_full):\n",
    "    X_train, X_test = X_full[train_index], X_full[test_index]\n",
    "    y_train, y_test = target_violent[train_index], target_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    lgm.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = lgm.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "lgm_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "dd2fe458-2d7e-478c-a63d-f1f74ea423c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370.7586193420597"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "250e1abb-6f14-4f0f-bc6d-10cf4d001969",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores = []\n",
    "ada = AdaBoostRegressor(learning_rate = 0.07, n_estimators = 40)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_violent):\n",
    "    X_train, X_test = X_violent[train_index], X_violent[test_index]\n",
    "    y_train, y_test = target_violent[train_index], target_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = ada.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "ada_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3ef640de-1a72-4e16-a55c-92f6212785ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394.7626900382202"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069bf50-9aa6-4e12-89ed-03d2270b543b",
   "metadata": {},
   "source": [
    "Non-Violent Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d08b4f61-7dc9-4219-b24f-b3c014788113",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=400, max_features = 'sqrt', max_depth = 20)\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_n_violent):\n",
    "    X_train, X_test = X_n_violent[train_index], X_n_violent[test_index]\n",
    "    y_train, y_test = target_n_violent[train_index], target_n_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "rf_fv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1c3f71dc-e36b-4508-a42f-154138fad967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875.372560786954"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "9a19e780-6b82-40b4-a0f5-953f6a55247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "num_estimators = 4000\n",
    "\n",
    "bst = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=num_estimators,\n",
    "    max_depth = 5\n",
    ")\n",
    "\n",
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_n_violent):\n",
    "    X_train, X_test = X_n_violent[train_index], X_n_violent[test_index]\n",
    "    y_train, y_test = target_n_violent[train_index], target_n_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    bst.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = bst.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "bst_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e13b5540-4b2f-4275-9096-c69e8f69371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1918.4830681913486"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "0995ebfa-ac89-4aa1-ac29-ebdeddcc999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 10\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "lgm = LGBMRegressor(boosting_type='gbdt',\n",
    "                   num_leaves=17,\n",
    "                   learning_rate = 0.1,\n",
    "                   n_estimators=100,\n",
    "                   verbose=0)\n",
    "mse_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_n_violent):\n",
    "    X_train, X_test = X_n_violent[train_index], X_n_violent[test_index]\n",
    "    y_train, y_test = target_n_violent[train_index], target_n_violent[test_index]\n",
    "\n",
    "    # Fit the Random Forest model on the training data\n",
    "    lgm.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = lgm.predict(X_test)\n",
    "\n",
    "    # Calculate MSE and store it\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "lgm_rv = np.sqrt(np.mean(mse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "58e891f2-57a3-48f6-9c5a-51ff01189a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1880.1056933011275"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abca108-ef42-43a4-a17e-1891b9928e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
